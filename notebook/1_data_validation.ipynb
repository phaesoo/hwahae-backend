{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(\"https://grepp-programmers-challenges.s3.ap-northeast-2.amazonaws.com/2020-birdview/ingredient-data.json\")\n",
    "ingr_list = json.loads(response.content.decode(\"utf-8\"))\n",
    "ingr_df = pd.DataFrame.from_dict(ingr_list)\n",
    "\n",
    "# unify with lower case as above\n",
    "ingr_df[\"name\"] = ingr_df[\"name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score(mark):\n",
    "    if mark == \"O\":\n",
    "        return 1\n",
    "    elif mark == \"X\":\n",
    "        return -1\n",
    "    elif mark == \"\":\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected mark: {}\".format(mark))\n",
    "        \n",
    "for column in ingr_df.columns:\n",
    "    if column == \"name\":\n",
    "        continue\n",
    "    ingr_df[column] = ingr_df[column].map(convert_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for validation object(valid_df), calculate each score by skin_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(\"https://grepp-programmers-challenges.s3.ap-northeast-2.amazonaws.com/2020-birdview/item-data.json\")\n",
    "item_list = json.loads(response.content.decode(\"utf-8\"))\n",
    "item_df = pd.DataFrame.from_dict(item_list).astype({\"price\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingredients would be better to unified with lower case for comparing purpose\n",
    "item_df[\"ingredients\"] = item_df[\"ingredients\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df[\"oily\"] = 0\n",
    "item_df[\"sensitive\"] = 0\n",
    "item_df[\"dry\"] = 0\n",
    "\n",
    "results = list()\n",
    "for index in range(0, len(item_df.index)):\n",
    "    item_srs = item_df.iloc[index]\n",
    "    ingr_list = list(set(item_srs[\"ingredients\"].split(\",\")))\n",
    "    \n",
    "    item_oily_score = 0\n",
    "    item_sensitive_score = 0\n",
    "    item_dry_score = 0\n",
    "    for ingr in ingr_list:\n",
    "        row_df = ingr_df[ingr_df[\"name\"] == ingr]\n",
    "        if len(row_df) != 1:\n",
    "            raise ValueError\n",
    "        row_srs = row_df.iloc[-1]\n",
    "\n",
    "        item_oily_score += row_srs[\"oily\"]\n",
    "        item_sensitive_score += row_srs[\"sensitive\"]\n",
    "        item_dry_score += row_srs[\"dry\"]\n",
    "        \n",
    "    results.append([item_srs[\"id\"], item_srs[\"category\"], item_srs[\"price\"], item_oily_score, item_sensitive_score, item_dry_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.DataFrame(results, columns=[\"id\", \"category\", \"price\", \"oily\", \"sensitive\", \"dry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation, compare results between data from django server and valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proceed: 0.00 %\n",
      "proceed: 3.33 %\n",
      "proceed: 6.67 %\n",
      "proceed: 10.00 %\n",
      "proceed: 13.33 %\n",
      "proceed: 16.67 %\n",
      "proceed: 20.00 %\n",
      "proceed: 23.33 %\n",
      "proceed: 26.67 %\n",
      "proceed: 30.00 %\n",
      "proceed: 33.33 %\n",
      "proceed: 36.67 %\n",
      "proceed: 40.00 %\n",
      "proceed: 43.33 %\n",
      "proceed: 46.67 %\n",
      "proceed: 50.00 %\n",
      "proceed: 53.33 %\n",
      "proceed: 56.67 %\n",
      "proceed: 60.00 %\n",
      "proceed: 63.33 %\n",
      "proceed: 66.67 %\n",
      "proceed: 70.00 %\n",
      "proceed: 73.33 %\n",
      "proceed: 76.67 %\n",
      "proceed: 80.00 %\n",
      "proceed: 83.33 %\n",
      "proceed: 86.67 %\n",
      "proceed: 90.00 %\n",
      "proceed: 93.33 %\n",
      "proceed: 96.67 %\n"
     ]
    }
   ],
   "source": [
    "loop = 0\n",
    "\n",
    "for _id in range(1, 1001):\n",
    "    for skin_type in [\"oily\", \"sensitive\", \"dry\"]:\n",
    "        if loop % 100 == 0:\n",
    "            print (\"proceed: {:.2f} %\".format(loop/3000.0 * 100.0))\n",
    "        try:\n",
    "            response = requests.get(\"http://127.0.0.1:8000/test/data/{}?skin_type={}\".format(_id, skin_type))\n",
    "            target_data = json.loads(response.content.decode(\"utf-8\"))\n",
    "            main_item = target_data[0]\n",
    "            sub_items = target_data[1:]\n",
    "            assert len(sub_items) == 3\n",
    "\n",
    "            # validate main\n",
    "            main_srs = valid_df[item_df[\"id\"] == _id].iloc[-1]\n",
    "            assert main_srs[\"id\"] == main_item[\"id\"], \"{}, {}\".format(main_srs[\"id\"], main_item[\"id\"])\n",
    "            assert main_srs[\"category\"] == main_item[\"category\"], \"{}, {}\".format(main_srs[\"category\"], main_item[\"category\"])\n",
    "            assert main_srs[\"price\"] == main_item[\"price\"], \"{}, {}\".format(main_srs[\"price\"], main_item[\"price\"])\n",
    "\n",
    "            # validate sub (recommended)\n",
    "            category = main_item[\"category\"]\n",
    "\n",
    "            sub_df = valid_df[valid_df[\"category\"] == category].sort_values(by=[skin_type, \"price\"], ascending=[False, True]).head(3)\n",
    "            assert len(sub_df) == 3\n",
    "\n",
    "            for index, sub_dict in enumerate(sub_items):\n",
    "                sub_srs = sub_df.iloc[index]\n",
    "                assert sub_srs[\"id\"] == sub_dict[\"id\"], \"{}, {}\".format(sub_srs[\"id\"], sub_dict[\"id\"])\n",
    "                assert sub_srs[skin_type] == sub_dict[\"score\"], \"{}, {}\".format(sub_srs[skin_type], sub_dict[\"score\"])\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            print (_id, skin_type)\n",
    "            print (target_data)\n",
    "            raise ValueError\n",
    "        loop += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dump valid_df into cache for unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.to_pickle(\"./test/valid.pickle\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
